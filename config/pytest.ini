[pytest]
# Pytest configuration for automotive test framework

# Test discovery patterns
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Test paths
testpaths = tests

# Exclude patterns (avoid collecting template files as tests)
norecursedirs =
    .git
    .tox
    dist
    build
    *.egg
    framework/templates
    scripts

# Minimum Python version
minversion = 3.9

# Command line options (always applied)
addopts =
    # Verbose output
    -v
    # Show local variables in tracebacks
    --showlocals
    # Show summary of all test outcomes
    -ra
    # Strict markers (fail on unknown markers)
    --strict-markers
    # Strict config (fail on unknown config options)
    --strict-config
    # Capture method (fd=file descriptors, more reliable for hardware tests)
    --capture=no
    # Warnings
    -W ignore::DeprecationWarning
    # Timeout for tests (5 minutes default)
    --timeout=300
    # Generate JUnit XML for CI/CD
    --junit-xml=reports/junit.xml
    # Generate HTML report
    --html=reports/report.html
    --self-contained-html

# Markers for test organization
markers =
    # Execution scope
    smoke: Critical smoke tests that must pass
    regression: Regression test suite
    integration: Integration tests
    performance: Performance and load tests
    
    # Domain-specific
    can_bus: CAN bus communication tests
    diagnostics: UDS/diagnostic protocol tests
    network: Network and Ethernet tests
    serial: Serial/UART communication tests
    gpio: GPIO control tests
    sensors: Sensor reading tests
    system: System-level tests
    
    # Platform-specific
    platform_a: Tests specific to Platform A hardware
    platform_b: Tests specific to Platform B hardware
    all_platforms: Tests that run on all platforms
    
    # Priority levels
    critical: Must-pass critical tests
    high: High priority tests
    medium: Medium priority tests
    low: Low priority tests
    
    # Special markers
    slow: Tests that take significant time
    requires_hardware: Tests requiring actual hardware (not mocked)
    wip: Work in progress tests (skipped by default)

    # Dynamic markers (from test registry)
    mock_adapter: Mock adapter specific tests
    spi_test: SPI interface tests
    cli_tests: CLI interface tests
    platform_ecu_platform_a: Platform A specific tests
    platform_ecu_platform_b: Platform B specific tests
    platform_mock_platform: Mock platform tests
    platform_custom_cli_platform: Custom CLI platform tests

# Timeout settings
timeout = 300
timeout_method = thread

# Logging
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] [%(name)s] %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

log_file = reports/pytest.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] [%(name)s] (%(filename)s:%(lineno)d) %(message)s
log_file_date_format = %Y-%m-%d %H:%M:%S

# Console output
console_output_style = progress

# Filterwarnings
filterwarnings =
    error::UserWarning
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning

# Coverage (when using pytest-cov)
[coverage:run]
source = framework
omit = 
    */tests/*
    */venv/*
    */__pycache__/*

[coverage:report]
precision = 2
show_missing = true
skip_covered = false

[coverage:html]
directory = reports/coverage
